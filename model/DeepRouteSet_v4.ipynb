{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepRouteSet\n",
    "DeepRouteSet uses LSTM to generate new moonboard problem. \n",
    "It is modified from the homework \"Improvise a Jazz Solo with an LSTM Network\" of Coursera course \"Sequence Model\".\n",
    "Yi-Shiou Duh(Allenduh@stanford.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "from DeepRouteSetHelper import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: all data preparation should be moved out of here to preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data preparation\n",
    "\n",
    "We want more moonboard problems, and high-quality, hard moonboard problem is especially not enough. Thanksfully, with LSTM, we can generate unlimited problems. By carefully choosing the source of author and 3 stars high quality problems, we can generate new moonboard problem of better quality.\n",
    "\n",
    "\n",
    "### 1.1 - Dataset\n",
    "\n",
    "We will train our RNN using a sequence of moves. We already preprocessed moonboard problems from a set of holds (e.g., [8A, 11B, 13C, ...]) to the list of holds with designated hand operation (e.g., [8A-LH, 11B-RH...]). Each point will be assigned to a moonboard \"value\". After training, RNN will then be able to generate new move sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Define Path to read handString_seq\n",
    "\n",
    "5 files: Handsequence (benchmark YN/ grade YN) and raw data with URL: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path().cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_handString_seq_path = cwd.parent / 'preprocessing' / 'benchmark_handString_seq_X'\n",
    "benchmarkNoGrade_handString_seq_path = cwd.parent / 'preprocessing' / 'benchmarkNoGrade_handString_seq_X'\n",
    "nonbenchmark_handString_seq_path = cwd.parent / 'preprocessing' / 'nonbenchmark_handString_seq_X'\n",
    "nonbenchmarkNoGrade_handString_seq_path = cwd.parent / 'preprocessing' / 'nonbenchmarkNoGrade_handString_seq_X'\n",
    "\n",
    "url_data_path = cwd.parent / 'raw_data' / 'moonGen_scrape_2016_cp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(benchmark_handString_seq_path, 'rb') as f:\n",
    "    benchmark_handString_seq = pickle.load(f)\n",
    "with open(benchmarkNoGrade_handString_seq_path, 'rb') as f:\n",
    "    benchmarkNoGrade_handString_seq = pickle.load(f)\n",
    "with open(nonbenchmark_handString_seq_path, 'rb') as f:\n",
    "    nonbenchmark_handString_seq = pickle.load(f)\n",
    "with open(nonbenchmarkNoGrade_handString_seq_path, 'rb') as f:\n",
    "    nonbenchmarkNoGrade_handString_seq = pickle.load(f)   \n",
    "with open(url_data_path, 'rb') as f:\n",
    "    MoonBoard_2016_withurl = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B4-LH', 'D6-RH', 'F9-LH', 'G11-RH', 'C15-LH', 'H18-RH']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of input sequence\n",
    "benchmark_handString_seq[\"189344\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem_name': 'JUST TRAINING',\n",
       " 'info': ['Alex Biale',\n",
       "  '195 climbers have repeated this problem',\n",
       "  '7C+ (User grade 8A)',\n",
       "  'Feet follow hands',\n",
       "  ''],\n",
       " 'url': 'https://moonboard.com/Problems/View/189344/just-training',\n",
       " 'num_empty': 0,\n",
       " 'num_stars': 3,\n",
       " 'moves': [{'Id': 1879483,\n",
       "   'Description': 'B4',\n",
       "   'IsStart': True,\n",
       "   'IsEnd': False},\n",
       "  {'Id': 1879484, 'Description': 'C15', 'IsStart': False, 'IsEnd': False},\n",
       "  {'Id': 1879485, 'Description': 'D6', 'IsStart': True, 'IsEnd': False},\n",
       "  {'Id': 1879486, 'Description': 'F9', 'IsStart': False, 'IsEnd': False},\n",
       "  {'Id': 1879487, 'Description': 'G11', 'IsStart': False, 'IsEnd': False},\n",
       "  {'Id': 1879488, 'Description': 'H18', 'IsStart': False, 'IsEnd': True}],\n",
       " 'grade': '7C+',\n",
       " 'UserGrade': '8A',\n",
       " 'isBenchmark': True,\n",
       " 'repeats': 195,\n",
       " 'ProblemType': 'Crimp',\n",
       " 'IsMaster': False,\n",
       " 'setter': {'Id': '7A90397F-74F9-4858-846B-D3CA9E4F70FF',\n",
       "  'Nickname': 'Alex Biale',\n",
       "  'Firstname': 'Alex',\n",
       "  'Lastname': 'Biale',\n",
       "  'City': 'Boulder',\n",
       "  'Country': 'CO',\n",
       "  'ProfileImageUrl': '/Content/Account/Images/default-profile.png?637231526210174359',\n",
       "  'CanShareData': True}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw data URL file looks like\n",
    "MoonBoard_2016_withurl[\"189344\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Pick good moonboard problem \n",
    "\n",
    "Only pick the problem by choosing good setter and pick 3 starts problems. Store in the goodKeyList\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collect Name of all setters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All setter with non error name\n",
    "setterList = []\n",
    "countNumOfErrorUsername = 0\n",
    "for key in MoonBoard_2016_withurl.keys():\n",
    "    try:\n",
    "        setterList.append(MoonBoard_2016_withurl[key]['setter']['Nickname'])\n",
    "    except:\n",
    "        countNumOfErrorUsername += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Count how many problems each setter has set and add to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Counter(setterList)    \n",
    " \n",
    "# TODO: reverse true? this means we are iterating in increasing number of problems - would be faster to do it in decreasing order\n",
    "setterDict = {k: v for k, v in sorted(Counter(setterList).items(), key=lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add experienced setter and Benchmark setter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total good setter:  425\n"
     ]
    }
   ],
   "source": [
    "# add setter with 50+ experience or Benchmark setter\n",
    "goodSetterName = []\n",
    "for key in setterDict.keys():\n",
    "    if setterDict[key] > 50:\n",
    "        goodSetterName.append(key)\n",
    "for key in MoonBoard_2016_withurl.keys(): \n",
    "    try:\n",
    "        if MoonBoard_2016_withurl[key]['isBenchmark'] == True:\n",
    "            goodSetterName.append(MoonBoard_2016_withurl[key]['setter']['Nickname'])\n",
    "    except:\n",
    "        pass\n",
    "print(\"Total good setter: \", len(goodSetterName))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a goodProblemKeyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of good problems:  19842\n"
     ]
    }
   ],
   "source": [
    "# Pick Extended BenchMark, high repeat number, author make many problem, high rate\n",
    "count = 0\n",
    "goodProblemKeyList = []\n",
    "for key in MoonBoard_2016_withurl.keys():  \n",
    "    try:\n",
    "        if MoonBoard_2016_withurl[key][isBenchmark] == True:\n",
    "            goodSetterName.append(MoonBoard_2016_withurl[key]['setter']['Nickname'])   \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "for key in MoonBoard_2016_withurl.keys():  \n",
    "    try:\n",
    "        if MoonBoard_2016_withurl[key]['setter']['Nickname'] in goodSetterName:\n",
    "            goodProblemKeyList.append(key)\n",
    "            count = count + 1\n",
    "        if MoonBoard_2016_withurl[key]['isBenchmark'] == True:\n",
    "            goodProblemKeyList.append(key)\n",
    "            count = count + 1\n",
    "        if MoonBoard_2016_withurl[key]['repeats'] > 50:\n",
    "            goodProblemKeyList.append(key)\n",
    "            count = count + 1\n",
    "        if MoonBoard_2016_withurl[key]['num_stars'] == 3:\n",
    "            goodProblemKeyList.append(key) \n",
    "            count = count + 1\n",
    "    except:\n",
    "        pass\n",
    "print (\"Total amount of good problems: \", count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Grade filter\n",
    "\n",
    "We will seperate problems into 3 difficulty range: Hard (V8 and up) medium (V6 to V8) and easy (V4 V5). So that our training set has the similar difficulty. This will help the problems generated to be more consistant in the difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: model is split into 3 different versions for different grade ranges, reduces training data size\n",
    "# TODO: it could be better to add the grade as a feature, which would allow the model to learn connection between grade and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of easy problems: 9839\n",
      "num of medium problems: 8267\n",
      "num of hard problems: 4639\n"
     ]
    }
   ],
   "source": [
    "easyProblemKeyList = []\n",
    "mediumProblemKeyList = []\n",
    "hardProblemKeyList = []\n",
    "for key in goodProblemKeyList:\n",
    "#     TODO: this results in only graded problems being used in training\n",
    "    if MoonBoard_2016_withurl[key]['grade'] in [\"6B+\", \"6C\", \"6C+\"]: # V4 V5\n",
    "        easyProblemKeyList.append(key)\n",
    "    if MoonBoard_2016_withurl[key]['grade'] in [\"7A\", \"7A+\", \"7B\", \"7B+\"]: # V6 7 8\n",
    "        mediumProblemKeyList.append(key)\n",
    "    if MoonBoard_2016_withurl[key]['grade'] in [\"7B\", \"7B+\", \"7C\", \"7C+\", \"8A\", \"8A+\", \"8B\"]: # V8 9 10 11 12 13\n",
    "        hardProblemKeyList.append(key)        \n",
    "print(\"num of easy problems:\", len(easyProblemKeyList)) \n",
    "print(\"num of medium problems:\", len(mediumProblemKeyList))\n",
    "print(\"num of hard problems:\", len(hardProblemKeyList))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Collect good and proper grade range into handString training set\n",
    "Collect into handStringList as input of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define handStringList and add benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benchmark training example:  358\n"
     ]
    }
   ],
   "source": [
    "# ensemble to a StringList\n",
    "print(\"Number of benchmark training example: \", len(benchmark_handString_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now add more problems and add more Benchmark problem to emphasize Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a proper grade level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "handStringList = collectHandStringIntoList(mediumProblemKeyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total training example (filter):  6681\n"
     ]
    }
   ],
   "source": [
    "# Total training sample\n",
    "numOfTrainingSample = len(handStringList)\n",
    "print(\"Number of total training example (filter): \", numOfTrainingSample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 - construct total reservoir of all avalible holds\n",
    "Create two dictionaries: \n",
    "* holdStr_to_holdIx: \"J5-LH\" has index =  127\n",
    "* holdIx_to_holdStr: index 277 is hold B15-RH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can reload the dictionaries here (Skipe the later cells) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd.parent / \"raw_data\" / \"holdStr_to_holdIx\", 'rb') as f:\n",
    "    holdStr_to_holdIx = pickle.load(f)\n",
    "with open(cwd.parent / \"raw_data\" / \"holdIx_to_holdStr\", 'rb') as f:\n",
    "    holdIx_to_holdStr = pickle.load(f)  \n",
    "numOfPossibleHolds = 277"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Code to regenerate maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rewrite, very slow\n",
    "# # Merge all string to big list to know how many string to consider\n",
    "# holdsReservoir = [] \n",
    "# for i in range(len(handStringList)):\n",
    "#     holdsReservoir = holdsReservoir + handStringList[i]\n",
    "# #holdsReservoir = sorted(holdsReservoir)  It will be great to sort the num of String from bottom to top.  \n",
    "# holdsReservoir = list(set(holdsReservoir)) # Delete repetitive string\n",
    "# print('Total holds avalible (include L / R): ', len(holdsReservoir))\n",
    "# numOfPossibleHolds = len(holdsReservoir)\n",
    "\n",
    "# # Build a dictionary convert String \"J5-LH\" to index\n",
    "# holdStr_to_holdIx = {}\n",
    "# holdStr_to_holdIx[\"End\"] = 0  # End hold\n",
    "# for i in range(len(holdsReservoir)):\n",
    "#     holdStr_to_holdIx[holdsReservoir[i]] = i + 1\n",
    "# print('For example, \"J5-LH\" has index = ', holdStr_to_holdIx[\"J5-LH\"])   \n",
    "\n",
    "# holdIx_to_holdStr = {v: k for k, v in holdStr_to_holdIx.items()}\n",
    "# print('Reverse dictionary: index 23 is hold', holdIx_to_holdStr[23])  \n",
    "\n",
    "# save_pickle(holdStr_to_holdIx, cwd / 'holdStr_to_holdIx')\n",
    "# save_pickle(holdIx_to_holdStr, cwd / 'holdIx_to_holdStr')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 - Prepare RNN's inputXY \n",
    "Use loadSeqXYFromString to shift Y from X by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 6681\n",
      "Tx (length of sequence): 12\n",
      "total # of unique values: 278\n",
      "shape of X: (6681, 12, 278)\n",
      "Shape of Y: (12, 6681, 278)\n"
     ]
    }
   ],
   "source": [
    "X, Y, n_values = loadSeqXYFromString(handStringList, holdStr_to_holdIx, m = numOfTrainingSample, maxNumOfHands = 12, numOfPossibleHolds = numOfPossibleHolds)\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('shape of X:', X.shape)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `X`: This is an `(m, Tx, n_values)` dimensional array. \n",
    "    - We have m training examples, each of which has `T_x=12` holds (if < 12 remainder are `\"End\"`/`0`). \n",
    "    - At each move step, the input is one of n_values different possible values, represented as a one-hot vector. \n",
    "        - For example, `X[i,t,:]` is a one-hot vector representing the hold at sequence position `t`. \n",
    "\n",
    "- `Y`: a `(Ty, m, n_values)` dimensional array\n",
    "    - This is essentially the same as `X`, but shifted one step to the left (to the previous move). \n",
    "    - Notice that the data in `Y` is **permuted** to be dimension `(Ty, m, n_values)`, where `Ty = Tx`. This format makes it more convenient to feed into the LSTM later.\n",
    "    - Similar to the music generator, we're using the previous values to predict the next value.\n",
    "        - So our sequence model will try to predict $y^{\\langle t \\rangle}$ given $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$. \n",
    "\n",
    "- `n_values`: The number of unique values in this dataset. This should be `n_values`. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 - Overview of our model\n",
    "\n",
    "* $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\cdots, x^{\\langle T_x \\rangle})$ is a window of size $T_x$ scanned over the climbing moves. \n",
    "* Each $x^{\\langle t \\rangle}$ is an index corresponding to a value.\n",
    "* $\\hat{y}^{t}$ is the prediction for the next value.\n",
    "* We will be training the model on random 12 values padded  with `\"End\"` if the climbing problem end before. \n",
    "    - We are setting each of the snippets to have the same length $T_x = 12$ to make vectorization easier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of parts 2 and 3 (If you already trained the model, skip to Prediction part 4)\n",
    "\n",
    "\n",
    "- We're going to train a model that predicts the next hold in a style that is similar to the climbing problems that it's trained on.  The training is contained in the weights and biases of the model. \n",
    "- In Part 3, we're then going to use those weights and biases in a new model which predicts a series of holds, using the previous hold to predict the next hold. \n",
    "- The weights and biases are transferred to the new model using 'global shared layers' described below\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building the model (If you already trained the model, skip to Prediction part)\n",
    "\n",
    "* Build and train a model that will learn climbing moves patterns. \n",
    "* The model takes input X of shape $(m, T_x, n_values)$ and labels Y of shape $(T_y, m, n_values)$. \n",
    "* We will use an LSTM with hidden states that have $n_{a} = 64$ dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dimensions for the hidden state of each LSTM cell.\n",
    "n_a = 64 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Sequence generation uses a for-loop\n",
    "* If you're building an RNN where, at test time, the entire input sequence $x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\ldots, x^{\\langle T_x \\rangle}$ is given in advance, then Keras has simple built-in functions to build the model. \n",
    "* However, for **sequence generation, at test time we don't know all the values of $x^{\\langle t\\rangle}$ in advance**.\n",
    "* Instead we generate them one at a time using $x^{\\langle t\\rangle} = y^{\\langle t-1 \\rangle}$. \n",
    "    * The input at time `t` is the prediction at the previous time step `t-1`.\n",
    "\n",
    "#### Shareable weights\n",
    "* The function `routeSetmodel()` will call the LSTM layer $T_x$ times using a for-loop.\n",
    "* It is important that all $T_x$ copies have the same weights. \n",
    "    - The $T_x$ steps should have shared weights that aren't re-initialized.\n",
    "* Referencing a globally defined shared layer will utilize the same layer-object instance at each time step.\n",
    "* Benefits of using shareable weights:\n",
    "    - reduced computation and space requirements\n",
    "    - theoretically has the ability to memorize long-term dependencies\n",
    "    - we may however learn more complex patterns if we don't share weights which is unlikely to require much more computation as we only generate 12 holds \n",
    "\n",
    "\n",
    "The key steps for implementing layers with shareable weights in Keras are: \n",
    "1. Define the layer objects (we will use global variables for this).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "#### 3 types of global variables layers:\n",
    "- [Reshape()](https://keras.io/layers/core/#reshape): Reshapes an output to a certain shape.\n",
    "- [LSTM()](https://keras.io/layers/recurrent/#lstm): Long Short-Term Memory layer\n",
    "- [Dense()](https://keras.io/layers/core/#dense): A regular fully-connected neural network layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: testing and reconsideration of shared weights\n",
    "reshapor = Reshape((1, n_values))\n",
    "LSTM_cell = LSTM(n_a, return_state = True)        \n",
    "densor = Dense(n_values, activation='softmax')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs \n",
    "* The `Input()` layer is used for defining the input `X` as well as the initial hidden state 'a0' and cell state `c0`.\n",
    "* The `shape` parameter takes a tuple that does not include the batch dimension (`m`).\n",
    "```Python\n",
    "X = Input(shape=(Tx, n_values)) # X has 3 dimensions and not 2: (m, Tx, n_values)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Outputs \n",
    "- Create an empty list `outputs` to save the outputs of the LSTM Cell at every time step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Loop through time steps\n",
    "* Loop for $t \\in 1, \\ldots, T_x$:\n",
    "\n",
    "#### 2A. Select the `t` time-step vector from `X`.\n",
    "* `X` has the shape `(m, Tx, n_values)`.\n",
    "* The shape of the `t` selection should be `(n_values,)`.\n",
    "\n",
    "#### 2B. Reshape `x` to be `(1,n_values)`.\n",
    "* Use the `reshapor()` layer.  It is a function that takes the previous layer as its input argument.\n",
    "\n",
    "#### 2C. Run `x` through one step of LSTM_cell.\n",
    "* Initialize the `LSTM_cell` with the previous step's hidden state `a` and cell state `c`. \n",
    "* Use the following formatting:\n",
    "```python\n",
    "next_hidden_state, _, next_cell_state = LSTM_cell(inputs=input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "```\n",
    "\n",
    "#### 2D. Dense layer\n",
    "* Propagate the LSTM's hidden state through a dense+softmax layer using `densor`. \n",
    "    \n",
    "#### 2E. Append output\n",
    "* Append the output to the list of `outputs`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: After the loop, create the model\n",
    "* Use the Keras `Model` object to create a model.\n",
    "* specify the inputs and outputs:\n",
    "```Python\n",
    "model = Model(inputs=[input_x, initial_hidden_state, initial_cell_state], outputs=the_outputs)\n",
    "```\n",
    "* Choose the appropriate variables for the input tensor, hidden state, cell state, and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepRouteSet(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Training model for route generation we reuse these  weights with a different network in order to generate routes\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the climbing route (padded by \"End\" up to this length)\n",
    "    n_a -- the number of activations used by the LSTM cells in our model\n",
    "    n_values -- number of unique values in the climbing move data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras instance model with n_a activations\n",
    "    \"\"\"\n",
    "    # TODO: think this needs to be reverted to use layers passed as inputs so weights can be used later without loading\n",
    "    reshapor = Reshape((1, n_values))\n",
    "    LSTM_cell = LSTM(n_a, return_state = True)\n",
    "    densor = Dense(n_values, activation='softmax')\n",
    "    \n",
    "    # Define the input layer and specify the shape\n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define the initial hidden state a0 and initial cell state c0\n",
    "    # using `Input`\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    # Step 1: Create empty list to append the outputs while you iterate\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):      \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda z: z[:, t, :])(X)   \n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values)\n",
    "        x = reshapor(x)  # from (?, n_values) to (?, 1, n_values)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs = x, initial_state = [a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs = [X, a0, c0], outputs = outputs)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model object\n",
    "* Run the following cell to define your model. \n",
    "* We will use `Tx=12`, `n_a=64` (the dimension of the LSTM activations), and `n_values=n_values`. \n",
    "* This cell may take a few seconds to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepRouteSet(Tx = 12 , n_a = 64, n_values = n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12, 278)]    0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 278)       0           ['lambda[0][0]',                 \n",
      "                                                                  'lambda_1[0][0]',               \n",
      "                                                                  'lambda_2[0][0]',               \n",
      "                                                                  'lambda_3[0][0]',               \n",
      "                                                                  'lambda_4[0][0]',               \n",
      "                                                                  'lambda_5[0][0]',               \n",
      "                                                                  'lambda_6[0][0]',               \n",
      "                                                                  'lambda_7[0][0]',               \n",
      "                                                                  'lambda_8[0][0]',               \n",
      "                                                                  'lambda_9[0][0]',               \n",
      "                                                                  'lambda_10[0][0]',              \n",
      "                                                                  'lambda_11[0][0]']              \n",
      "                                                                                                  \n",
      " a0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 64),         87808       ['reshape_1[0][0]',              \n",
      "                                 (None, 64),                      'a0[0][0]',                     \n",
      "                                 (None, 64)]                      'c0[0][0]',                     \n",
      "                                                                  'reshape_1[1][0]',              \n",
      "                                                                  'lstm_1[0][0]',                 \n",
      "                                                                  'lstm_1[0][2]',                 \n",
      "                                                                  'reshape_1[2][0]',              \n",
      "                                                                  'lstm_1[1][0]',                 \n",
      "                                                                  'lstm_1[1][2]',                 \n",
      "                                                                  'reshape_1[3][0]',              \n",
      "                                                                  'lstm_1[2][0]',                 \n",
      "                                                                  'lstm_1[2][2]',                 \n",
      "                                                                  'reshape_1[4][0]',              \n",
      "                                                                  'lstm_1[3][0]',                 \n",
      "                                                                  'lstm_1[3][2]',                 \n",
      "                                                                  'reshape_1[5][0]',              \n",
      "                                                                  'lstm_1[4][0]',                 \n",
      "                                                                  'lstm_1[4][2]',                 \n",
      "                                                                  'reshape_1[6][0]',              \n",
      "                                                                  'lstm_1[5][0]',                 \n",
      "                                                                  'lstm_1[5][2]',                 \n",
      "                                                                  'reshape_1[7][0]',              \n",
      "                                                                  'lstm_1[6][0]',                 \n",
      "                                                                  'lstm_1[6][2]',                 \n",
      "                                                                  'reshape_1[8][0]',              \n",
      "                                                                  'lstm_1[7][0]',                 \n",
      "                                                                  'lstm_1[7][2]',                 \n",
      "                                                                  'reshape_1[9][0]',              \n",
      "                                                                  'lstm_1[8][0]',                 \n",
      "                                                                  'lstm_1[8][2]',                 \n",
      "                                                                  'reshape_1[10][0]',             \n",
      "                                                                  'lstm_1[9][0]',                 \n",
      "                                                                  'lstm_1[9][2]',                 \n",
      "                                                                  'reshape_1[11][0]',             \n",
      "                                                                  'lstm_1[10][0]',                \n",
      "                                                                  'lstm_1[10][2]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 278)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 278)          18070       ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_1[1][0]',                 \n",
      "                                                                  'lstm_1[2][0]',                 \n",
      "                                                                  'lstm_1[3][0]',                 \n",
      "                                                                  'lstm_1[4][0]',                 \n",
      "                                                                  'lstm_1[5][0]',                 \n",
      "                                                                  'lstm_1[6][0]',                 \n",
      "                                                                  'lstm_1[7][0]',                 \n",
      "                                                                  'lstm_1[8][0]',                 \n",
      "                                                                  'lstm_1[9][0]',                 \n",
      "                                                                  'lstm_1[10][0]',                \n",
      "                                                                  'lstm_1[11][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 105,878\n",
      "Trainable params: 105,878\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check model\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training\n",
    "- optimizer: AdamW\n",
    "- loss: categorical cross-entropy (for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamW(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can either load pre-trained model or train it again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(cwd.parent / 'model' / 'DeepRouteSetMedium_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize hidden state and cell state\n",
    "Finally, let's initialize `a0` and `c0` for the LSTM's initial state to be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = numOfTrainingSample\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "* Lets now fit the model! \n",
    "* We will turn `Y` into a list, since the cost function expects `Y` to be provided in this format \n",
    "    - `list(Y)` is a list with `Tx` items, where each of the list items is of shape (numOfTrainingSample,n_values). \n",
    "    - Lets train for 100 epochs. This will take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit([X, a0, c0], list(Y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add tesorflow callback, training checkpoints and early stopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generating moonboard problem\n",
    "\n",
    "We already have trained model which has learned the patterns of climbing move and route set spirit. Lets now use this model to synthesize new route.\n",
    "Importantly we reuse the `LSTM_cell` and `densor` layers from the model we trained.\n",
    "\n",
    "### 3.1 - The inference model\n",
    "\n",
    "At each step of sampling:\n",
    "* Take as input the activation '`a`' and cell state '`c`' from the previous state of the LSTM.\n",
    "* Forward propagate by one step.\n",
    "* Get a new output activation as well as cell state. \n",
    "* The new activation '`a`' can then be used to generate the output using the fully connected layer, `densor`. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample x to be the one-hot version of '`out`'. \n",
    "* This allows you to pass it to the next LSTM's step.  \n",
    "* use the add_one function inside of the Lambda function\n",
    "```py\n",
    "result = Lambda(add_one)(input_var)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepRouteSetPred(LSTM_cell, densor, n_values = n_values, n_a = 64, Ty = 12):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, number of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    def one_hot(x):\n",
    "        x = K.argmax(x)\n",
    "        x = tf.one_hot(x, n_values) \n",
    "        x = RepeatVector(1)(x)\n",
    "        return x\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell\n",
    "        # TODO: this is using the same LSTM_cell for all time steps?\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, n_values)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: \n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        # See instructions above.\n",
    "        x = Lambda(one_hot)(out)\n",
    "        \n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\"\n",
    "    inference_model = Model(inputs = [x0, a0, c0], outputs = outputs)\n",
    "        \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = deepRouteSetPred(LSTM_cell, densor, n_values = n_values, n_a = 64, Ty = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1, 278)]     0           []                               \n",
      "                                                                                                  \n",
      " a0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64),         87808       ['input_2[0][0]',                \n",
      "                                 (None, 64),                      'a0[0][0]',                     \n",
      "                                 (None, 64)]                      'c0[0][0]',                     \n",
      "                                                                  'lambda_12[0][0]',              \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[0][2]',                   \n",
      "                                                                  'lambda_13[0][0]',              \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[1][2]',                   \n",
      "                                                                  'lambda_14[0][0]',              \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[2][2]',                   \n",
      "                                                                  'lambda_15[0][0]',              \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[3][2]',                   \n",
      "                                                                  'lambda_16[0][0]',              \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[4][2]',                   \n",
      "                                                                  'lambda_17[0][0]',              \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[5][2]',                   \n",
      "                                                                  'lambda_18[0][0]',              \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[6][2]',                   \n",
      "                                                                  'lambda_19[0][0]',              \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[7][2]',                   \n",
      "                                                                  'lambda_20[0][0]',              \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[8][2]',                   \n",
      "                                                                  'lambda_21[0][0]',              \n",
      "                                                                  'lstm[9][0]',                   \n",
      "                                                                  'lstm[9][2]',                   \n",
      "                                                                  'lambda_22[0][0]',              \n",
      "                                                                  'lstm[10][0]',                  \n",
      "                                                                  'lstm[10][2]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 278)          18070       ['lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[9][0]',                   \n",
      "                                                                  'lstm[10][0]',                  \n",
      "                                                                  'lstm[11][0]']                  \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)             (None, 1, 278)       0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)             (None, 1, 278)       0           ['dense[1][0]']                  \n",
      "                                                                                                  \n",
      " lambda_14 (Lambda)             (None, 1, 278)       0           ['dense[2][0]']                  \n",
      "                                                                                                  \n",
      " lambda_15 (Lambda)             (None, 1, 278)       0           ['dense[3][0]']                  \n",
      "                                                                                                  \n",
      " lambda_16 (Lambda)             (None, 1, 278)       0           ['dense[4][0]']                  \n",
      "                                                                                                  \n",
      " lambda_17 (Lambda)             (None, 1, 278)       0           ['dense[5][0]']                  \n",
      "                                                                                                  \n",
      " lambda_18 (Lambda)             (None, 1, 278)       0           ['dense[6][0]']                  \n",
      "                                                                                                  \n",
      " lambda_19 (Lambda)             (None, 1, 278)       0           ['dense[7][0]']                  \n",
      "                                                                                                  \n",
      " lambda_20 (Lambda)             (None, 1, 278)       0           ['dense[8][0]']                  \n",
      "                                                                                                  \n",
      " lambda_21 (Lambda)             (None, 1, 278)       0           ['dense[9][0]']                  \n",
      "                                                                                                  \n",
      " lambda_22 (Lambda)             (None, 1, 278)       0           ['dense[10][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 105,878\n",
      "Trainable params: 105,878\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the inference model\n",
    "inference_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Initialization of inference model\n",
    "The following code creates the zero-valued vectors you will use to initialize `x` and the LSTM state variables `a` and `c`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initializer = np.random.rand(1, 1, n_values) / 100\n",
    "a_initializer = np.random.rand(1, n_a) * 150\n",
    "c_initializer = np.random.rand(1, n_a) /2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - `predict_and_sample()`\n",
    "\n",
    "Generates a new climb using the inference model and a set of intial hidden and cell states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, n_values), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, n_values), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices =  np.argmax(pred, axis = 2)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (Ty, n_values)\n",
    "    results =  to_categorical(indices, num_classes = np.shape(x_initializer)[2])\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save to json format \n",
    "# model_json = inference_model.to_json()\n",
    "# with open(\"DeepRouteSetMedium_v2.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # save to h5 format    \n",
    "# inference_model.save_weights(\"DeepRouteSetMedium_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\valsp\\source\\repos\\MoonBoardRNN\\model\\DeepRouteSet\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\valsp\\source\\repos\\MoonBoardRNN\\model\\DeepRouteSet\\assets\n"
     ]
    }
   ],
   "source": [
    "# create DeepRouteSet directory if it doesn't exist\n",
    "model_dir = cwd / 'DeepRouteSet'\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir()\n",
    "\n",
    "# save the complete inference model architecture and weights\n",
    "inference_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Prediction with pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - DeepRouteSet generated one problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By runing following two cells, you can now insert those into moonboard app and create new problems to see the layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weight (loaded directly from the saved model, no need to reuse layer)\n",
    "inference_model.load_weights(cwd / \"DeepRouteSetMedium_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "np.argmax(results[2]) = 76\n",
      "np.argmax(results[7]) = 0\n",
      "list(indices[2:8]) = [array([76], dtype=int64), array([242], dtype=int64), array([134], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "#Initial conditions like x,a,c can be changed\n",
    "x_initializer = np.random.rand(1, 1, n_values) / 100\n",
    "a_initializer = np.random.rand(1, n_a) * 150\n",
    "c_initializer = np.random.rand(1, n_a) /2\n",
    "\n",
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[2]) =\", np.argmax(results[2]))\n",
    "print(\"np.argmax(results[7]) =\", np.argmax(results[7]))\n",
    "print(\"list(indices[2:8]) =\", list(indices[2:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepRouteSet's generated problem:\n",
      "A5-LH\n",
      "A5-RH\n",
      "B9-RH\n",
      "C13-LH\n",
      "D18-RH\n",
      "End\n",
      "End\n",
      "End\n",
      "End\n",
      "End\n",
      "End\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print(\"DeepRouteSet's generated problem:\")\n",
    "for i in range(12):\n",
    "    print(holdIx_to_holdStr[int(indices[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Sanity Check \n",
    "Check and filter out some of the not right problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " ['A5-LH', 'A5-RH', 'B9-RH', 'C13-LH', 'D18-RH'],\n",
       " [72, 248, 76, 242, 134])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanityCheckAndOutput(indices, holdIx_to_holdStr, handStringList, printError=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Plot 40 generated moonboard problems\n",
    "Plot 40 generated moonboard problems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try:\n",
    "1. change x, a, c initializer and see how it behave\n",
    "2. Change the how many more benchmark should add into training set. Now it is 6 duplicate of benchMark problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Repeat hand error ['E6-LH', 'E6-RH']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Warning: Second match hand with third ['K5-RH', 'F5-LH', 'F5-RH', 'B8-LH', 'F10-RH', 'E13-LH', 'H14-RH', 'F15-LH', 'H18-RH']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Warning: Too high start ['H8-LH', 'J10-RH', 'F5-LH', 'F5-RH', 'J10-RH', 'F13-LH', 'J16-RH', 'D18-LH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Repeat hand error ['B4-LH', 'D5-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "['C5-LH', 'C5-RH', 'B6-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Repeat hand error ['F5-LH', 'F5-RH']\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Warning: Second match hand with third ['F10-RH', 'J5-LH', 'J5-RH', 'H8-RH', 'E12-LH', 'I14-RH', 'E16-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Warning: Second match hand with third ['G9-LH', 'F5-LH', 'F5-RH', 'G8-RH', 'C10-LH', 'F12-RH', 'C14-LH', 'G18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Warning: Second match hand with third ['K5-RH', 'F5-LH', 'F5-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Repeat hand error ['E6-LH', 'E6-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "['D3-RH', 'B4-LH', 'D6-RH', 'C7-LH', 'G11-RH', 'D13-LH', 'D16-RH', 'C18-LH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['C13-LH', 'F5-LH', 'F5-RH', 'H10-RH', 'C13-LH', 'D15-RH', 'D18-LH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Warning: Second match hand with third ['E8-LH', 'F5-LH', 'F5-RH', 'H11-RH', 'E15-LH', 'G18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Repeat hand error ['H10-LH', 'F5-LH', 'J9-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Warning: Second match hand with third ['K8-LH', 'F5-LH', 'F5-RH', 'C10-LH', 'G14-RH', 'D18-LH']\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Warning: Second match hand with third ['H8-LH', 'F5-LH', 'F5-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "['G2-LH', 'G2-RH', 'E6-LH', 'H8-RH', 'C10-LH', 'E12-RH', 'A14-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['H5-RH', 'E6-LH', 'E6-RH', 'H8-RH', 'G9-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Repeat hand error ['H5-LH', 'D5-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "['B4-LH', 'C5-RH', 'B6-LH', 'E9-RH', 'F10-LH', 'H12-RH', 'G15-LH', 'I18-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['H5-RH', 'E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "['K5-LH', 'K5-RH', 'G6-LH', 'J9-RH', 'F13-LH', 'H14-RH', 'D18-LH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['K5-RH', 'F5-LH', 'F5-RH', 'C10-LH', 'F11-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Repeat hand error ['F7-LH', 'F5-LH', 'F5-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "No end error ['G4-LH', 'G4-RH', 'E6-LH', 'E6-RH', 'C8-LH', 'F11-RH', 'C13-LH', 'H5-LH', 'K5-RH', 'G6-LH', 'J9-RH']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Warning: Second match hand with third ['F5-RH', 'A5-LH', 'A5-RH', 'D8-RH', 'D13-LH', 'F15-RH', 'C18-LH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['G9-LH', 'F5-LH', 'F5-RH', 'C7-LH', 'F10-RH', 'C12-LH', 'H14-RH', 'F15-LH', 'H18-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['H5-RH', 'E6-LH', 'E6-RH', 'C8-LH', 'F10-RH', 'D11-LH', 'G14-RH', 'E16-LH', 'I18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "['B4-LH', 'D5-RH', 'E6-LH', 'F10-RH', 'D11-LH', 'I13-RH', 'G15-LH', 'K18-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Warning: Second match hand with third ['B3-RH', 'A5-LH', 'A5-RH', 'E8-RH', 'C10-LH', 'G14-RH', 'G15-LH', 'K18-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Repeat hand error ['H5-LH', 'H5-RH', 'D5-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Too high start ['H8-RH', 'F10-LH', 'H12-RH', 'D15-LH', 'D18-RH']\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Warning: Second match hand with third ['B10-LH', 'G4-LH', 'G4-RH', 'E6-LH', 'H8-RH', 'G9-LH', 'I11-RH', 'G14-LH', 'K16-RH', 'K18-LH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "['C5-LH', 'C5-RH', 'A5-LH', 'E8-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'I14-RH', 'G18-LH']\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Repeat hand error ['E6-LH', 'D5-RH', 'C6-LH', 'D5-RH', 'B8-LH', 'D5-RH']\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Warning: Second match hand with third ['I5-RH', 'F5-LH', 'F5-RH', 'H11-RH', 'E15-LH', 'E18-RH']\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Warning: Second match hand with third ['G18-RH']\n",
      "10 valid out of 40\n"
     ]
    }
   ],
   "source": [
    "NUM_GEN = 40\n",
    "passCount = 0\n",
    "passGeneratedHandSequenceList = []\n",
    "for i in range(NUM_GEN):\n",
    "    x_initializer = np.zeros((1, 1, n_values))\n",
    "    x_initializer = np.random.rand(1, 1, n_values) / 100\n",
    "    a_initializer = np.random.rand(1, n_a) * 150\n",
    "    c_initializer = np.random.rand(1, n_a) /2\n",
    "    \n",
    "    results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "    passCheck, outputListInString, outputListInIx = sanityCheckAndOutput(\n",
    "        indices, holdIx_to_holdStr, handStringList, printError = True)\n",
    "    if passCheck: \n",
    "        print(outputListInString)\n",
    "        # plotAProblem(outputListInString)\n",
    "        passCount = passCount + 1\n",
    "        passGeneratedHandSequenceList.append(outputListInString)\n",
    "print (f\"{passCount} valid out of {NUM_GEN}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(passGeneratedHandSequenceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n"
     ]
    }
   ],
   "source": [
    "print(passGeneratedHandSequenceList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Produce move generator\n",
    "To feed into GradeNet, we should transform from hand sequence to move sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed in the hold feature.csv files\n",
    "left_hold_feature_path = cwd.parent / 'raw_data' / 'HoldFeature2016LeftHand.csv'\n",
    "right_hold_feature_path = cwd.parent / 'raw_data' / 'HoldFeature2016RightHand.csv'\n",
    "\n",
    "LeftHandfeatures = pd.read_csv(left_hold_feature_path, dtype=str)\n",
    "RightHandfeatures = pd.read_csv(right_hold_feature_path, dtype=str)\n",
    "# convert features from pd dataframe to dictionary of left and right hand\n",
    "RightHandfeature_dict = {}\n",
    "LeftHandfeature_dict = {}\n",
    "for index in RightHandfeatures.index:\n",
    "    LeftHandfeature_item = LeftHandfeatures.loc[index]\n",
    "    LeftHandfeature_dict[(int(LeftHandfeature_item['X_coord']), int(LeftHandfeature_item['Y_coord']))] = np.array(\n",
    "        list(LeftHandfeature_item['Difficulties'])).astype(int)\n",
    "    RightHandfeature_item = RightHandfeatures.loc[index]\n",
    "    RightHandfeature_dict[(int(RightHandfeature_item['X_coord']), int(RightHandfeature_item['Y_coord']))] = np.array(\n",
    "        list(RightHandfeature_item['Difficulties'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'TargetHoldString': (5, 6),\n",
       "  'TargetHoldHand': 0,\n",
       "  'TargetHoldScore': array([5]),\n",
       "  'RemainingHoldString': (8, 5),\n",
       "  'RemainingHoldHand': 1,\n",
       "  'RemainingHoldScore': array([3]),\n",
       "  'dxdyRtoT': (-3, 1),\n",
       "  'MovingHoldString': (7, 4),\n",
       "  'MovingHoldHand': 0,\n",
       "  'MovingHoldScore': array([6]),\n",
       "  'dxdyMtoT': (-2, 2),\n",
       "  'FootPlacement': [0, 0, 0, 1, 1, 1, 0],\n",
       "  'MoveSuccessRate': array([13.928304])},\n",
       " {'TargetHoldString': (9, 9),\n",
       "  'TargetHoldHand': 1,\n",
       "  'TargetHoldScore': array([5]),\n",
       "  'RemainingHoldString': (5, 6),\n",
       "  'RemainingHoldHand': 0,\n",
       "  'RemainingHoldScore': array([5]),\n",
       "  'dxdyRtoT': (4, 3),\n",
       "  'MovingHoldString': (8, 5),\n",
       "  'MovingHoldHand': 1,\n",
       "  'MovingHoldScore': array([3]),\n",
       "  'dxdyMtoT': (1, 4),\n",
       "  'FootPlacement': [0, 0, 1, 0, 0, 0, 1],\n",
       "  'MoveSuccessRate': array([9.18649979])},\n",
       " {'TargetHoldString': (5, 12),\n",
       "  'TargetHoldHand': 0,\n",
       "  'TargetHoldScore': array([3]),\n",
       "  'RemainingHoldString': (9, 9),\n",
       "  'RemainingHoldHand': 1,\n",
       "  'RemainingHoldScore': array([5]),\n",
       "  'dxdyRtoT': (-4, 3),\n",
       "  'MovingHoldString': (5, 6),\n",
       "  'MovingHoldHand': 0,\n",
       "  'MovingHoldScore': array([5]),\n",
       "  'dxdyMtoT': (0, 6),\n",
       "  'FootPlacement': [1, 0, 0, 1, 1, 0, 0],\n",
       "  'MoveSuccessRate': array([5.51189988])},\n",
       " {'TargetHoldString': (7, 13),\n",
       "  'TargetHoldHand': 1,\n",
       "  'TargetHoldScore': array([5]),\n",
       "  'RemainingHoldString': (5, 12),\n",
       "  'RemainingHoldHand': 0,\n",
       "  'RemainingHoldScore': array([3]),\n",
       "  'dxdyRtoT': (2, 1),\n",
       "  'MovingHoldString': (9, 9),\n",
       "  'MovingHoldHand': 1,\n",
       "  'MovingHoldScore': array([5]),\n",
       "  'dxdyMtoT': (-2, 4),\n",
       "  'FootPlacement': [0, 0, 1, 0, 1, 0, 1],\n",
       "  'MoveSuccessRate': array([10.55312802])},\n",
       " {'TargetHoldString': (4, 15),\n",
       "  'TargetHoldHand': 0,\n",
       "  'TargetHoldScore': array([4]),\n",
       "  'RemainingHoldString': (7, 13),\n",
       "  'RemainingHoldHand': 1,\n",
       "  'RemainingHoldScore': array([5]),\n",
       "  'dxdyRtoT': (-3, 2),\n",
       "  'MovingHoldString': (5, 12),\n",
       "  'MovingHoldHand': 0,\n",
       "  'MovingHoldScore': array([3]),\n",
       "  'dxdyMtoT': (-1, 3),\n",
       "  'FootPlacement': [0, 0, 0, 0, 0, 1, 1],\n",
       "  'MoveSuccessRate': array([18.54642783])},\n",
       " {'TargetHoldString': (8, 17),\n",
       "  'TargetHoldHand': 1,\n",
       "  'TargetHoldScore': array([6]),\n",
       "  'RemainingHoldString': (4, 15),\n",
       "  'RemainingHoldHand': 0,\n",
       "  'RemainingHoldScore': array([4]),\n",
       "  'dxdyRtoT': (4, 2),\n",
       "  'MovingHoldString': (7, 13),\n",
       "  'MovingHoldHand': 1,\n",
       "  'MovingHoldScore': array([5]),\n",
       "  'dxdyMtoT': (1, 4),\n",
       "  'FootPlacement': [0, 1, 1, 0, 0, 1, 1],\n",
       "  'MoveSuccessRate': array([16.33165002])}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output with a list of dictionary means moves\n",
    "moveGeneratorFromStrList(['H5-LH', 'I6-RH', 'F7-LH', 'J10-RH', 'F13-LH', 'H14-RH', 'E16-LH', 'I18-RH'], string_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 - Generate moves and save the result (Don't overwrite)\n",
    "Two things to save:\n",
    "1. Move sequence -- For GradeNet and StyleNet purpose\n",
    "2. List of holds -- For ploting purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = cwd / 'MediumProblemOfDeepRouteSet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result saved. Store  9 out of 10\n"
     ]
    }
   ],
   "source": [
    "dim22Vec, listOfSavedSequence = moveGeneratorForAllGeneratedProblem(passGeneratedHandSequenceList, save_path, \"HardDeepRouteSet_v1_id\", print_result = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.          2.          3.          0.        ]\n",
      " [ 9.         12.         14.         17.        ]\n",
      " [ 1.          0.          1.          0.        ]\n",
      " [ 5.          8.          4.          5.        ]\n",
      " [ 4.          5.          2.          3.        ]\n",
      " [ 5.          9.         12.         14.        ]\n",
      " [ 5.          5.          8.          4.        ]\n",
      " [ 1.         -3.          1.         -3.        ]\n",
      " [ 4.          3.          2.          3.        ]\n",
      " [ 4.          4.          5.          2.        ]\n",
      " [ 5.          5.          9.         12.        ]\n",
      " [ 3.          5.          5.          8.        ]\n",
      " [ 1.         -2.         -2.         -2.        ]\n",
      " [ 4.          7.          5.          5.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          1.        ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 1.          0.          0.          0.        ]\n",
      " [ 1.          1.          0.          0.        ]\n",
      " [ 1.          0.          0.          1.        ]\n",
      " [ 0.          0.          1.          1.        ]\n",
      " [ 1.13008937 20.01687593 10.50692437 10.00843797]]\n"
     ]
    }
   ],
   "source": [
    "print(dim22Vec[next(iter(dim22Vec))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim22Vec[next(iter(dim22Vec))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(listOfSavedSequence, cwd / 'MediumProblemSequenceOfDeepRouteSet_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Plot stored file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd.parent / \"out\" / \"MediumProblemSequenceOfDeepRouteSet_v1\", 'rb') as f:\n",
    "    listOfSavedSequence = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E6-LH', 'E6-RH', 'I10-RH', 'C13-LH', 'E16-RH', 'A18-LH']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfSavedSequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediumRouteSet_v1_id 1\n",
      "beta ['E6-LH', 'E6-RH', 'I10-RH', 'C13-LH', 'E16-RH', 'A18-LH']\n",
      "MediumRouteSet_v1_id 2\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'H8-RH', 'F10-LH', 'H12-RH', 'G15-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 3\n",
      "beta ['G2-LH', 'G2-RH', 'F5-LH', 'F5-RH', 'B8-LH', 'F10-RH', 'E13-LH', 'H14-RH', 'E18-LH']\n",
      "MediumRouteSet_v1_id 4\n",
      "beta ['A5-LH', 'A5-RH', 'D5-RH', 'B8-LH', 'F10-RH', 'F12-LH', 'J13-RH', 'G15-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 5\n",
      "beta ['A5-LH', 'C5-RH', 'B6-LH', 'E9-RH', 'D11-LH', 'I14-RH', 'E18-LH']\n",
      "MediumRouteSet_v1_id 6\n",
      "beta ['K5-LH', 'K5-RH', 'G6-LH', 'J9-RH', 'F14-LH', 'E18-RH']\n",
      "MediumRouteSet_v1_id 7\n",
      "beta ['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 8\n",
      "beta ['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'E16-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 9\n",
      "beta ['E6-LH', 'E6-RH', 'H8-RH', 'C10-LH', 'G14-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 10\n",
      "beta ['A5-LH', 'A5-RH', 'C5-LH', 'E8-RH', 'F10-LH', 'H12-RH', 'G15-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 11\n",
      "beta ['C5-LH', 'C5-RH', 'E6-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'I14-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 12\n",
      "beta ['B4-LH', 'C5-RH', 'D6-RH', 'A9-LH', 'F11-RH', 'F13-LH', 'H16-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 13\n",
      "beta ['A5-LH', 'E6-RH', 'C10-LH', 'C13-LH', 'E18-RH']\n",
      "MediumRouteSet_v1_id 14\n",
      "beta ['B4-LH', 'C5-RH', 'D6-RH', 'D10-LH', 'G11-RH', 'F15-LH', 'H18-RH']\n",
      "MediumRouteSet_v1_id 15\n",
      "beta ['A5-RH', 'C5-LH', 'E6-RH', 'C8-LH', 'F11-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 16\n",
      "beta ['F5-LH', 'F5-RH', 'F10-RH', 'C13-LH', 'E16-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 17\n",
      "beta ['F5-LH', 'F5-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 18\n",
      "beta ['F5-LH', 'F5-RH', 'A5-LH', 'B8-LH', 'F10-RH', 'E13-LH', 'I14-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 19\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'H8-RH', 'E9-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 20\n",
      "beta ['F5-LH', 'F5-RH', 'C10-LH', 'F11-RH', 'F14-LH', 'I18-RH']\n",
      "MediumRouteSet_v1_id 21\n",
      "beta ['F5-LH', 'F5-RH', 'B8-LH', 'F10-RH', 'E13-LH', 'I16-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 22\n",
      "beta ['C5-LH', 'C5-RH', 'D6-RH', 'B8-LH', 'F10-RH', 'F12-LH', 'H14-RH', 'F15-LH', 'H18-RH']\n",
      "MediumRouteSet_v1_id 23\n",
      "beta ['D3-RH', 'B4-LH', 'D6-RH', 'C7-LH', 'G11-RH', 'D13-LH', 'D16-RH', 'C18-LH']\n",
      "MediumRouteSet_v1_id 24\n",
      "beta ['G2-LH', 'G2-RH', 'H5-LH', 'H5-RH', 'E8-LH', 'E9-RH', 'D10-LH', 'I12-RH', 'F15-LH', 'H18-RH']\n",
      "MediumRouteSet_v1_id 25\n",
      "beta ['A5-LH', 'A5-RH', 'D5-RH', 'B8-LH', 'F10-RH', 'F12-LH', 'J13-RH', 'H16-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 26\n",
      "beta ['E6-LH', 'E6-RH', 'F11-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 27\n",
      "beta ['F5-LH', 'F5-RH', 'J8-RH', 'F10-LH', 'I13-RH', 'G15-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 28\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'G9-RH', 'C10-LH', 'G14-RH', 'E16-LH', 'I18-RH']\n",
      "MediumRouteSet_v1_id 29\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'G9-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n",
      "MediumRouteSet_v1_id 30\n",
      "beta ['E6-LH', 'E6-RH', 'E8-LH', 'F10-RH', 'C13-LH', 'H14-RH', 'H16-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 31\n",
      "beta ['G2-LH', 'G2-RH', 'F5-LH', 'F5-RH', 'B8-LH', 'E10-RH', 'A12-LH', 'E13-RH', 'B16-LH', 'G18-RH']\n",
      "MediumRouteSet_v1_id 32\n",
      "beta ['J5-LH', 'J5-RH', 'E6-LH', 'H8-RH', 'E9-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 33\n",
      "beta ['K5-LH', 'K5-RH', 'G6-LH', 'J9-RH', 'F13-LH', 'H14-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 34\n",
      "beta ['E6-LH', 'E6-RH', 'H8-RH', 'C10-LH', 'G14-RH', 'E16-LH', 'I18-RH']\n",
      "MediumRouteSet_v1_id 35\n",
      "beta ['F5-LH', 'F5-RH', 'J8-RH', 'E10-LH', 'I14-RH', 'E18-LH']\n",
      "MediumRouteSet_v1_id 36\n",
      "beta ['F5-LH', 'F5-RH', 'C5-LH', 'E6-RH', 'B8-LH', 'F10-RH', 'C13-LH', 'H14-RH', 'G15-LH', 'K18-RH']\n",
      "MediumRouteSet_v1_id 37\n",
      "beta ['G4-LH', 'G4-RH', 'E6-LH', 'E6-RH', 'C8-LH', 'F11-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 38\n",
      "beta ['A5-LH', 'C5-RH', 'E6-LH', 'G9-RH', 'D11-LH', 'I14-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 39\n",
      "beta ['E6-LH', 'E6-RH', 'G4-RH', 'E6-LH', 'E8-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'I14-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 40\n",
      "beta ['F5-RH', 'A5-LH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 41\n",
      "beta ['C5-LH', 'C5-RH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 42\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'E6-RH', 'E8-LH', 'H10-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n",
      "MediumRouteSet_v1_id 43\n",
      "beta ['J5-LH', 'J5-RH', 'E6-LH', 'G9-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n",
      "MediumRouteSet_v1_id 44\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'H8-RH', 'F10-LH', 'H12-RH', 'G15-LH', 'G17-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 45\n",
      "beta ['F5-LH', 'F5-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'I14-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 46\n",
      "beta ['J5-LH', 'J5-RH', 'G6-LH', 'I9-RH', 'F13-LH', 'H16-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 47\n",
      "beta ['F5-LH', 'F5-RH', 'C5-LH', 'E8-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'I14-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 48\n",
      "beta ['E6-LH', 'E6-RH', 'F10-RH', 'C13-LH', 'D15-RH', 'A18-LH']\n",
      "MediumRouteSet_v1_id 49\n",
      "beta ['G4-LH', 'G4-RH', 'E6-LH', 'H8-RH', 'C10-LH', 'E12-RH', 'A14-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 50\n",
      "beta ['K5-RH', 'F5-LH', 'I10-RH', 'C13-LH', 'E16-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 51\n",
      "beta ['J5-LH', 'J5-RH', 'G6-LH', 'I10-RH', 'F13-LH', 'H16-RH', 'D18-LH']\n",
      "MediumRouteSet_v1_id 52\n",
      "beta ['A5-RH', 'C5-LH', 'E8-RH', 'C10-LH', 'G14-RH', 'E18-LH']\n",
      "MediumRouteSet_v1_id 53\n",
      "beta ['B3-RH', 'A5-LH', 'E6-RH', 'C10-LH', 'G13-RH', 'E18-LH']\n",
      "MediumRouteSet_v1_id 54\n",
      "beta ['E6-LH', 'C5-RH', 'E6-LH', 'H8-RH', 'E9-LH', 'G10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 55\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'E6-RH', 'C8-LH', 'F11-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 56\n",
      "beta ['E6-LH', 'E6-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 57\n",
      "beta ['E6-LH', 'E6-RH', 'E8-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 58\n",
      "beta ['I5-RH', 'E6-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 59\n",
      "beta ['F6-LH', 'F5-RH', 'A5-LH', 'A5-RH', 'B8-LH', 'F10-RH', 'E13-LH', 'I16-RH', 'G18-LH']\n",
      "MediumRouteSet_v1_id 60\n",
      "beta ['A5-LH', 'A5-RH', 'B8-LH', 'F10-RH', 'E14-LH', 'G18-RH']\n",
      "MediumRouteSet_v1_id 61\n",
      "beta ['J5-LH', 'J5-RH', 'H8-RH', 'C10-LH', 'D15-RH', 'A18-LH']\n",
      "MediumRouteSet_v1_id 62\n",
      "beta ['C5-LH', 'C5-RH', 'A5-LH', 'F10-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 63\n",
      "beta ['H5-LH', 'H5-RH', 'E6-LH', 'E6-RH', 'A9-LH', 'F11-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 64\n",
      "beta ['B4-LH', 'C5-RH', 'E6-LH', 'G9-RH', 'C13-LH', 'D18-RH']\n",
      "MediumRouteSet_v1_id 65\n",
      "beta ['I5-RH', 'F5-LH', 'F10-RH', 'C13-LH', 'E16-RH', 'D18-LH']\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for seq in listOfSavedSequence:\n",
    "    print (\"MediumRouteSet_v1_id\", count)\n",
    "    print (\"beta\", seq)\n",
    "    plotAProblem(seq)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Space to play with**: \n",
    "\n",
    "* Initial conditions like x,a,c can be changed\n",
    "* Should compare the similarity with the training set. \n",
    "* Package the DeepRouteSet with gradeNet to predict the grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "This program is adapted from Andrew Ng coursera's course Jazz music\n",
    "The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim's GitHub repository.\n",
    "\n",
    "- Ji-Sung Kim, 2016, [deepjazz](https://github.com/jisungk/deepjazz)\n",
    "- Jon Gillick, Kevin Tang and Robert Keller, 2009. [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf)\n",
    "- Robert Keller and David Morrison, 2007, [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf)\n",
    "- Franois Pachet, 1999, [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "EG0F7",
   "launcher_item_id": "cxJXc"
  },
  "kernelspec": {
   "display_name": "moonboardrnn-hW4ed92X-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d257aaba97b534713eafa91609455863fac8d9daac4f63bd3ddeb8aecd89a62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
